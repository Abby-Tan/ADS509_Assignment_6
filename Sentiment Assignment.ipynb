{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADS 509\n",
    "#### Assignment 6\n",
    "#### Abby Tan\n",
    "#### GitHub Link: https://github.com/Abby-Tan/ADS509_Assignment_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import emoji\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"C:/Users/abby0/OneDrive/Documents/GitHub/ADS509_Assignment_6/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = []\n",
    "songs = []\n",
    "lyrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in artist_folders:\n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "    for f_name in artist_files:\n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile:\n",
    "            artists.append(artist)\n",
    "            songs.append(f_name)\n",
    "            lyrics.append(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = pd.DataFrame({'artists':artists,\n",
    "                          'songs'  :songs,\n",
    "                          'lyrics' :lyrics })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('joji_','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('postmalone_','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('.txt','')\n",
    "df_lyrics['songs'] = df_lyrics['songs'].str.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joji</td>\n",
       "      <td>amazonian pet</td>\n",
       "      <td>amazonian pet\\n\\nI'm an old man rich, amazonia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joji</td>\n",
       "      <td>attention</td>\n",
       "      <td>attention\\n\\nGirl, would it kill you just to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joji</td>\n",
       "      <td>bitter fuck</td>\n",
       "      <td>bitter fuck\\n\\nI find it hard to be myself\\nI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists          songs                                             lyrics\n",
       "0    Joji  amazonian pet  amazonian pet\\n\\nI'm an old man rich, amazonia...\n",
       "1    Joji      attention  attention\\n\\nGirl, would it kill you just to t...\n",
       "2    Joji    bitter fuck  bitter fuck\\n\\nI find it hard to be myself\\nI ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PostMalone_df = pd.read_csv(data_location + twitter_folder + 'PostMalone_follower_data.txt', sep='\\t')\n",
    "PostMalone_df['artists'] = 'PostMalone'\n",
    "PostMalone_df = PostMalone_df[['artists','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Joji_df = pd.read_csv(data_location + twitter_folder + 'sushitrash_follower_data.txt', sep='\\t')\n",
    "Joji_df['artists'] = 'Joji'\n",
    "Joji_df = Joji_df[['artists','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.concat([PostMalone_df, Joji_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>she/her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>She/Her 🇬🇧🇪🇺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>a math dracula • associate software developer ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artists                                        description\n",
       "0  PostMalone                                            she/her\n",
       "1  PostMalone                                       She/Her 🇬🇧🇪🇺\n",
       "2  PostMalone  a math dracula • associate software developer ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "pos_words = pd.read_csv(data_location + 'positive-words.txt', sep='\\t', encoding='latin-1')\n",
    "neg_words = pd.read_csv(data_location + 'negative-words.txt', sep='\\t', encoding='latin-1')\n",
    "tidy_sen = pd.read_csv(data_location + 'tidytext_sentiments.txt', sep='\\t', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative words\n",
    "pos_words = pos_words[33:]\n",
    "neg_words = neg_words[33:]\n",
    "\n",
    "pos_words['score'] = 1\n",
    "neg_words['score'] = -1\n",
    "\n",
    "pos_words.columns = ['word','score']\n",
    "neg_words.columns = ['word','score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy sentiments\n",
    "tidy_sen['score'] = np.where(tidy_sen['sentiment'] == 'positive', 1, -1)\n",
    "tidy_sen = tidy_sen[['word','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11539, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge\n",
    "df_sen = pd.concat([pos_words, neg_words, tidy_sen], axis=0)\n",
    "df_sen = df_sen.drop_duplicates().reset_index(drop=True)\n",
    "df_sen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abounds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  score\n",
       "0       a+      1\n",
       "1   abound      1\n",
       "2  abounds      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionary\n",
    "sen_word = df_sen['word'].to_list()\n",
    "sen_score = df_sen['score'].to_list()\n",
    "word_dict = dict(zip(sen_word, sen_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score\n",
    "\n",
    "def sen_score(text):\n",
    "    sentiment_score = 0\n",
    "    for word in text:\n",
    "        if word in word_dict: \n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(text)\n",
    "\n",
    "# Reference\n",
    "# Albrecht, J., Ramachandran, S., & Winkler, C. (2020, December 29). \n",
    "# Blueprints for Text Analytics Using Python: Machine Learning-Based Solutions for Common Real World (NLP) Applications (1st ed.). O’Reilly Media.\n",
    "# Page 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep pipeline\n",
    "\n",
    "punctuation = set(punctuation)\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def remove_punctuation(text, punct_set=punctuation) :\n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "sw = set([remove_punctuation(w) for w in sw])\n",
    "def remove_stop(tokens) :\n",
    "    return([t for t in tokens if t.lower() not in sw])\n",
    "\n",
    "def tokenize(text) :\n",
    "    return([t for t in whitespace_pattern.split(text) if t])\n",
    "\n",
    "def prepare(text, pipeline) :\n",
    "    tokens = str(text)\n",
    "    for transform in pipeline :\n",
    "        tokens = transform(tokens)\n",
    "    return(tokens)\n",
    "\n",
    "# Reference from module 3 assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lyrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics[\"tokens\"] = df_lyrics[\"lyrics\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lyrics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joji</td>\n",
       "      <td>amazonian pet</td>\n",
       "      <td>amazonian pet\\n\\nI'm an old man rich, amazonia...</td>\n",
       "      <td>[amazonian, pet, im, old, man, rich, amazonian...</td>\n",
       "      <td>-0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joji</td>\n",
       "      <td>attention</td>\n",
       "      <td>attention\\n\\nGirl, would it kill you just to t...</td>\n",
       "      <td>[attention, girl, would, kill, throw, little, ...</td>\n",
       "      <td>-0.033708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joji</td>\n",
       "      <td>bitter fuck</td>\n",
       "      <td>bitter fuck\\n\\nI find it hard to be myself\\nI ...</td>\n",
       "      <td>[bitter, fuck, find, hard, shed, skin, everybo...</td>\n",
       "      <td>-0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists          songs                                             lyrics  \\\n",
       "0    Joji  amazonian pet  amazonian pet\\n\\nI'm an old man rich, amazonia...   \n",
       "1    Joji      attention  attention\\n\\nGirl, would it kill you just to t...   \n",
       "2    Joji    bitter fuck  bitter fuck\\n\\nI find it hard to be myself\\nI ...   \n",
       "\n",
       "                                              tokens  lyrics_score  \n",
       "0  [amazonian, pet, im, old, man, rich, amazonian...     -0.073684  \n",
       "1  [attention, girl, would, kill, throw, little, ...     -0.033708  \n",
       "2  [bitter, fuck, find, hard, shed, skin, everybo...     -0.538462  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics['lyrics_score'] = df_lyrics['tokens'].apply(sen_score)\n",
    "df_lyrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Overall, which artist has the higher average sentiment per song? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: PostMalone has the higher average sentiment per song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artists\n",
       "Joji         -0.031590\n",
       "PostMalone   -0.013446\n",
       "Name: lyrics_score, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.groupby(['artists'])['lyrics_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: For your first artist, what songs have the highest and lowest sentiments? Print those songs to the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The following 2 songs have the highest and lowest sentiments for the first artist (Joji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_artist = df_lyrics[df_lyrics['artists'] == 'Joji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song has highest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joji</td>\n",
       "      <td>no fun</td>\n",
       "      <td>0.233766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists   songs  lyrics_score\n",
       "9    Joji  no fun      0.233766"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest sentiment\n",
    "print('The song has highest sentiment:')\n",
    "fst_artist[fst_artist['lyrics_score'] == fst_artist['lyrics_score'].max()][['artists','songs','lyrics_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song has lowest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joji</td>\n",
       "      <td>bitter fuck</td>\n",
       "      <td>-0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artists        songs  lyrics_score\n",
       "2    Joji  bitter fuck     -0.538462"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest sentiment\n",
    "print('The song has lowest sentiment:')\n",
    "fst_artist[fst_artist['lyrics_score'] == fst_artist['lyrics_score'].min()][['artists','songs','lyrics_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: For your second artist, what songs have the highest and lowest sentiments? Print those songs to the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The following 2 songs have the highest and lowest sentiments for the second artist (PostMalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_artist = df_lyrics[df_lyrics['artists'] == 'PostMalone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song has highest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>oh god</td>\n",
       "      <td>0.204301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artists   songs  lyrics_score\n",
       "37  PostMalone  oh god      0.204301"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest sentiment\n",
    "print('The song has highest sentiment:')\n",
    "scd_artist[scd_artist['lyrics_score'] == scd_artist['lyrics_score'].max()][['artists','songs','lyrics_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song has lowest sentiment:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>lyrics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>git wit u</td>\n",
       "      <td>-0.150538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artists      songs  lyrics_score\n",
       "27  PostMalone  git wit u     -0.150538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest sentiment\n",
    "print('The song has lowest sentiment:')\n",
    "scd_artist[scd_artist['lyrics_score'] == scd_artist['lyrics_score'].min()][['artists','songs','lyrics_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Plot the distributions of the sentiment scores for both artists. You can use seaborn to plot densities or plot histograms in matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artists\n",
       "Joji          AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "PostMalone    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: lyrics_score, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_lyrics.groupby('artists')['lyrics_score'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emoji sentiment data obtained from Kaggle\n",
    "\n",
    "https://www.kaggle.com/datasets/thomasseleck/emoji-sentiment-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionary for Q1 - word and emoji combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode codepoint</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Position</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Unicode name</th>\n",
       "      <th>Unicode block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>😂</td>\n",
       "      <td>0x1f602</td>\n",
       "      <td>14622</td>\n",
       "      <td>0.805101</td>\n",
       "      <td>3614</td>\n",
       "      <td>4163</td>\n",
       "      <td>6845</td>\n",
       "      <td>FACE WITH TEARS OF JOY</td>\n",
       "      <td>Emoticons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>❤</td>\n",
       "      <td>0x2764</td>\n",
       "      <td>8050</td>\n",
       "      <td>0.746943</td>\n",
       "      <td>355</td>\n",
       "      <td>1334</td>\n",
       "      <td>6361</td>\n",
       "      <td>HEAVY BLACK HEART</td>\n",
       "      <td>Dingbats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥</td>\n",
       "      <td>0x2665</td>\n",
       "      <td>7144</td>\n",
       "      <td>0.753806</td>\n",
       "      <td>252</td>\n",
       "      <td>1942</td>\n",
       "      <td>4950</td>\n",
       "      <td>BLACK HEART SUIT</td>\n",
       "      <td>Miscellaneous Symbols</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emoji Unicode codepoint  Occurrences  Position  Negative  Neutral  Positive  \\\n",
       "0     😂           0x1f602        14622  0.805101      3614     4163      6845   \n",
       "1     ❤            0x2764         8050  0.746943       355     1334      6361   \n",
       "2     ♥            0x2665         7144  0.753806       252     1942      4950   \n",
       "\n",
       "             Unicode name          Unicode block  \n",
       "0  FACE WITH TEARS OF JOY              Emoticons  \n",
       "1       HEAVY BLACK HEART               Dingbats  \n",
       "2        BLACK HEART SUIT  Miscellaneous Symbols  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emoji_sen = pd.read_csv(r'C:\\Users\\abby0\\OneDrive\\Documents\\GitHub\\ADS509_Assignment_6\\Emoji_Sentiment_Data_v1.0.csv')\n",
    "df_emoji_sen.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emoji_sen['sentiment'] = df_emoji_sen[['Negative','Neutral','Positive']].idxmax(axis=1)\n",
    "df_emoji_sen = df_emoji_sen[df_emoji_sen['sentiment'] != 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>❤</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>♥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  score\n",
       "0    😂      1\n",
       "1    ❤      1\n",
       "2    ♥      1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 100 positive emoji\n",
    "pos_emoji = df_emoji_sen[df_emoji_sen['sentiment'] == 'Positive']\n",
    "pos_emoji = pos_emoji.sort_values('Occurrences', ascending=False).head(100)[['Emoji']]\n",
    "pos_emoji['score'] = 1\n",
    "pos_emoji.columns = ['word', 'score']\n",
    "pos_emoji.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>😭</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>😩</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>😒</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  score\n",
       "4     😭     -1\n",
       "14    😩     -1\n",
       "23    😒     -1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 100 negative emoji\n",
    "neg_emoji = df_emoji_sen[df_emoji_sen['sentiment'] == 'Negative']\n",
    "neg_emoji = neg_emoji.sort_values('Occurrences', ascending=False).head(100)[['Emoji']]\n",
    "neg_emoji['score'] = -1\n",
    "neg_emoji.columns = ['word', 'score']\n",
    "neg_emoji.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sentiment for emoji and word\n",
    "df_sen_w_emoji = pd.concat([pos_emoji, neg_emoji, df_sen], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionary\n",
    "sen_word = df_sen_w_emoji['word'].to_list()\n",
    "sen_score = df_sen_w_emoji['score'].to_list()\n",
    "word_dict = dict(zip(sen_word, sen_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score\n",
    "\n",
    "def sen_score(text):\n",
    "    sentiment_score = 0\n",
    "    for word in text:\n",
    "        if word in word_dict: \n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / (len(text) or not len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionary for Q2 - emoji only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji only sentiment\n",
    "sen_emoji = pd.concat([pos_emoji, neg_emoji], axis=0)\n",
    "\n",
    "pos_emoji_list = pos_emoji['word'].tolist()\n",
    "neg_emoji_list = neg_emoji['word'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data clean for Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter[\"tokens\"] = df_twitter[\"description\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>description</th>\n",
       "      <th>tokens</th>\n",
       "      <th>twitter_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>she/her</td>\n",
       "      <td>[sheher]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>She/Her 🇬🇧🇪🇺</td>\n",
       "      <td>[sheher, 🇬🇧🇪🇺]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PostMalone</td>\n",
       "      <td>a math dracula • associate software developer ...</td>\n",
       "      <td>[math, dracula, •, associate, software, develo...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artists                                        description  \\\n",
       "0  PostMalone                                            she/her   \n",
       "1  PostMalone                                       She/Her 🇬🇧🇪🇺   \n",
       "2  PostMalone  a math dracula • associate software developer ...   \n",
       "\n",
       "                                              tokens  twitter_score  \n",
       "0                                           [sheher]            0.0  \n",
       "1                                     [sheher, 🇬🇧🇪🇺]            0.0  \n",
       "2  [math, dracula, •, associate, software, develo...            0.1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter['twitter_score'] = df_twitter['tokens'].apply(sen_score)\n",
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data clean for Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return(emoji.is_emoji(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert descrption to list\n",
    "\n",
    "    # PostMalone\n",
    "PostMalone_twitter = df_twitter[df_twitter['artists'] == 'PostMalone']\n",
    "PostMalone_desc_list = PostMalone_twitter['description'].tolist()\n",
    "\n",
    "    # Joji\n",
    "Joji_twitter = df_twitter[df_twitter['artists'] == 'Joji']\n",
    "Joji_desc_list = Joji_twitter['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji only lists\n",
    "\n",
    "    # PostMalone\n",
    "postmalone_emoji = []\n",
    "for text in PostMalone_desc_list:\n",
    "    if is_emoji(text):\n",
    "        postmalone_emoji.append(text)\n",
    "\n",
    "    # Joji\n",
    "joji_emoji = []\n",
    "for text in Joji_desc_list:\n",
    "    if is_emoji(text):\n",
    "        joji_emoji.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative emoji lists\n",
    "\n",
    "    # PostMalone\n",
    "postmalone_pos_emoji = [i for i in postmalone_emoji if i in pos_emoji_list]\n",
    "postmalone_neg_emoji = [i for i in postmalone_emoji if i in neg_emoji_list]\n",
    "\n",
    "    # Joji\n",
    "joji_pos_emoji = [i for i in joji_emoji if i in pos_emoji_list]\n",
    "joji_neg_emoji = [i for i in joji_emoji if i in neg_emoji_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('😎', 10)]\n",
      "[('💔', 3)]\n",
      "[('❤', 7)]\n",
      "[('➰', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(postmalone_pos_emoji).most_common(1))\n",
    "print(Counter(postmalone_neg_emoji).most_common(1))\n",
    "print(Counter(joji_pos_emoji).most_common(1))\n",
    "print(Counter(joji_neg_emoji).most_common(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: What is the average sentiment of your two artists?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Joji has average sentiment of 0.032379 and PostMalone has 0.059090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artists\n",
       "Joji          0.032379\n",
       "PostMalone    0.059090\n",
       "Name: twitter_score, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.groupby(['artists'])['twitter_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Which positive emoji is the most popular for each artist? Which negative emoji? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular positive emoji for PostMalone is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'😎'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most popular positive emoji for PostMalone is:')\n",
    "Counter(postmalone_pos_emoji).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular negative emoji for PostMalone is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'💔'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most popular negative emoji for PostMalone is:')\n",
    "Counter(postmalone_neg_emoji).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular positive emoji for Joji is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'❤'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most popular positive emoji for Joji is:')\n",
    "Counter(joji_pos_emoji).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular negative emoji for Joji is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'➰'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most popular negative emoji for Joji is:')\n",
    "Counter(joji_neg_emoji).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
